{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KgT3EnI0Pdpr","collapsed":true},"outputs":[],"source":["!pip install transformers tqdm more_itertools scikit-learn torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3BQUhKcGMVq"},"outputs":[],"source":["# Use this when working on the full entity dataset of 260_000 entities\n","# mention names aren't ordered inn a particular way, just what appears first in the documents\n","# we can have many duplicates, so in this case where we are only encoding the name we want to avoid that\n","# unique_mention_name_id_pairs = list({name: _id for name, _id in bc5cdr_name_id_pairs}.items())\n","# mention_names = unique_mention_name_id_pairs.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tznThHxyRAON"},"outputs":[],"source":["# this is the feature extraction pipeline so we can get the embeddings directly (we can only do inference with this, no fine-tuning)\n","from transformers import pipeline\n","\n","model_name = \"google-bert/bert-base-uncased\"\n","\n","# core model\n","extractor = pipeline(\"feature-extraction\", model=model_name, device='cuda')"]},{"cell_type":"code","source":["import torch\n","\n","# Setup the device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")  # This should say 'cuda'"],"metadata":{"id":"0Ykbtl8-Z38M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"spUPv5HAQBip"},"source":["### Move the model to the GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJxvpv2ck8cL"},"outputs":[],"source":["from datasets import load_dataset\n","\n","# there are all \"positive\" pairs\"\n","dataset = load_dataset(\"Stevenf232/BC5CDR_MeSH2015_name_and_aliases\")\n","train_pairs = dataset[\"train\"]"]},{"cell_type":"code","source":["def extract_features(extractor, pairs):\n","    ''' includes [CLS] pooling '''\n","    batch_size = 16\n","\n","    # Create generators (saves RAM compared to creating full lists)\n","    mention_gen = (p[\"mention\"] for p in pairs)\n","    entity_gen = (p[\"entity\"] for p in pairs)\n","\n","    mention_name_features = []\n","    entity_name_features = []\n","\n","\n","    print(\"Extracting mention features...\")\n","    for output in tqdm(extractor(mention_gen, batch_size=batch_size, truncation=True, padding=True, return_tensors='pt'), total=len(pairs)):\n","        # The pipeline yields one result at a time, but processes in batches on GPU\n","        cls_vector = output[0, 0, :].cpu()\n","        mention_name_features.append(cls_vector)\n","\n","    print(\"Extracting entity features...\")\n","    for output in tqdm(extractor(entity_gen, batch_size=batch_size, truncation=True, padding=True, return_tensors='pt'), total=len(pairs)):\n","        cls_vector = output[0, 0, :].cpu()\n","        entity_name_features.append(cls_vector)\n","\n","    return mention_name_features, entity_name_features"],"metadata":{"id":"ENbW8AnZcCpq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGY4DeS5-YOq"},"outputs":[],"source":["mention_cls, entity_cls = extract_features(extractor, train_pairs)"]},{"cell_type":"markdown","metadata":{"id":"CGcetMJgmsjs"},"source":["# Model evaluation"]},{"cell_type":"markdown","metadata":{"id":"kKp8QG9r5B73"},"source":["Potential issue - this finds relevance using Cosine Similarity (will it have bias towards fine-tuning on cosineSimilarityLoss vs other loss functions?)"]},{"cell_type":"code","source":["def evaluate(mention_cls, entity_cls, train_pairs):\n","    print(\"Processing vectors on GPU (CLS Pooling)...\")\n","\n","    # 1. Stack\n","    # Since they are already tensors, we just stack them.\n","    mentions_tensor = torch.stack(mention_cls).to('cuda')\n","    entities_tensor = torch.stack(entity_cls).to('cuda')\n","\n","    # --- 2. Normalize ---\n","    # Standardize vector length so Dot Product = Cosine Similarity\n","    mentions_norm = torch.nn.functional.normalize(mentions_tensor, p=2, dim=1)\n","    entities_norm = torch.nn.functional.normalize(entities_tensor, p=2, dim=1)\n","\n","    # --- 3. Matrix Multiplication ---\n","    # Compute similarity between ALL mentions and ALL entities instantly\n","    similarity_matrix = torch.mm(mentions_norm, entities_norm.T)\n","\n","    # --- 4. Find Best Matches ---\n","    # Returns the index of the highest score for each row\n","    top_indices = torch.argmax(similarity_matrix, dim=1).cpu().numpy()\n","\n","    # --- 5. Print Loop ---\n","    correct_count = 0\n","    print(\"\\n--- Starting Evaluation ---\\n\")\n","\n","    for i, top_idx in enumerate(top_indices):\n","        # the strange conversion to int from here on out is because the original idx is of type numpy.int64\n","        top_idx = int(top_idx)\n","        i = int(i)\n","\n","        top_match_id = train_pairs[top_idx][\"id\"]\n","        correct_id = train_pairs[i][\"id\"]\n","\n","        if top_match_id == correct_id:\n","            correct_count += 1\n","\n","        mention_name = train_pairs[i][\"mention\"]\n","        top_match = train_pairs[top_idx][\"entity\"]\n","        correct_name = train_pairs[i][\"entity\"]\n","\n","        print(f\"mention_name: {mention_name}\")\n","        print(f\"correct entity name: {correct_name}\")\n","        print(f\"top_match: {top_match}\")\n","        print(\"\")\n","\n","    # --- 6. Statistics ---\n","    accuracy = correct_count / len(train_pairs)\n","    print(f\"total comparisons: {len(train_pairs)}\")\n","    print(f\"correct comparisons: {correct_count}\")\n","    print(f\"accuracy: {accuracy:.4f}\")\n","\n","    return accuracy"],"metadata":{"id":"B_9WHcgSfkOT"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M57NXFT5PQgH"},"outputs":[],"source":["evaluate(mention_cls, entity_cls, train_pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WkV4mUza7zPp"},"outputs":[],"source":["# more evaluation methods\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","# print(f\"{accuracy_score(train_labels, predicted_labels)=:.3f}\")\n","# print(f\"{recall_score(train_labels, predicted_labels)=:.3f}\")\n","# print(f\"{precision_score(train_labels, predicted_labels)=:.3f}\")\n","# print(f\"{f1_score(train_labels, predicted_labels)=:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"Tg8bVWw7m2fL"},"source":["## Evaluating Fine-tuned model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XGh8CLlURCda"},"outputs":[],"source":["# finetuned model\n","# don't think I need a feature-extraction pipeline based on auto-generated docs: https://huggingface.co/Stevenf232/fine-tuned-SapBERT2\n","#from transformers import pipeline\n","\n","from sentence_transformers import SentenceTransformer\n","\n","fine_tuned_model_name = \"Stevenf232/fine-tuned-SapBERT4\"\n","model = SentenceTransformer(fine_tuned_model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNj9sQ-S-asd"},"outputs":[],"source":["from tqdm import tqdm\n","def encode(model, pairs):\n","  batch_size=16\n","  mention_encodings = []\n","  entity_encodings = []\n","\n","  for i in tqdm(range(0, len(pairs), batch_size), desc=\"Extracting features\"):\n","      # encode mentions\n","      batch = pairs[i:i + batch_size][\"mention\"]\n","      encodings = model.encode(batch, convert_to_tensor=True)\n","      mention_encodings.extend(encodings)\n","\n","      # encode entities\n","      batch = pairs[i:i + batch_size][\"entity\"]\n","      encodings = model.encode(batch, convert_to_tensor=True)\n","      entity_encodings.extend(encodings)\n","\n","  return mention_encodings, entity_encodings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJ6sDvTMTDqP"},"outputs":[],"source":["mention_encodings, entity_encodings = encode(model, train_pairs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xAs5NGaxPLVB"},"outputs":[],"source":["evaluate(mention_encodings, entity_encodings, train_pairs)"]}],"metadata":{"colab":{"gpuType":"T4","provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.5"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}