{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-Falkovsky/Hypencoder-Entity-Linking/blob/Professional-Structure/notebooks/fine_tune_Hypencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZYti28jtMlh",
        "outputId": "952b63cb-cb10-4931-bb38-b1e66c8322bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚òÅÔ∏è Running in Colab...\n",
            "Cloning into 'Hypencoder-Entity-Linking'...\n",
            "remote: Enumerating objects: 266, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (194/194), done.\u001b[K\n",
            "Receiving objects: 100% (266/266), 705.72 KiB | 2.88 MiB/s, done.\n",
            "remote: Total 266 (delta 116), reused 203 (delta 65), pack-reused 0 (from 0)\u001b[K\n",
            "Resolving deltas: 100% (116/116), done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hüìç Working Directory is now: /content/Hypencoder-Entity-Linking/hypencoder-paper\n",
            "‚úÖ Environment Ready!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import importlib.util\n",
        "\n",
        "# for syncing changes to notebook when changing something in VScode\n",
        "# deprecated/need to update to new IPython which breaks colab\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "\n",
        "\n",
        "\n",
        "REPO_NAME = \"Hypencoder-Entity-Linking\"\n",
        "GIT_URL = f\"https://github.com/Steve-Falkovsky/{REPO_NAME}.git\"\n",
        "\n",
        "\n",
        "# --- COLAB SETUP ---\n",
        "is_colab = importlib.util.find_spec(\"google.colab\") is not None\n",
        "if is_colab:\n",
        "    print(\"‚òÅÔ∏è Running in Colab...\")\n",
        "    if not os.path.exists(REPO_NAME):\n",
        "        !git clone {GIT_URL}\n",
        "\n",
        "    # Move into the downloaded repo (The Root)\n",
        "    os.chdir(REPO_NAME)\n",
        "\n",
        "\n",
        "\n",
        "# --- LOCAL SETUP ---\n",
        "else:\n",
        "    print(\"üíª Running Locally...\")\n",
        "    if os.path.basename(os.getcwd()) == \"notebooks\":\n",
        "        os.chdir(\"..\")\n",
        "\n",
        "\n",
        "%pip install -q -e \"./hypencoder-paper\"\n",
        "os.chdir(\"./hypencoder-paper\")\n",
        "\n",
        "print(f\"üìç Working Directory is now: {os.getcwd()}\")\n",
        "print(\"‚úÖ Environment Ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "8d286c5534ca479d8bf6ab9b06a9b5d7",
            "2f361811ecf340aeae1d26b81049478b",
            "318087e3cf80429bb0fa9046bc42b505",
            "0d531d3beaf341ecaec2042eebbe528e",
            "bfb58c7d516d4cdc8d5e4369c465ea7d",
            "006879de96104873bfa440e94370422e",
            "2733f621c7a0468cbad121bb593a7852",
            "d58e3c43c6214e918717ae7e9ca2af06",
            "5a76d3f1e4d142edb05166d0b4210bf6",
            "fdda7719605c42a7b4c4d64488aa340f",
            "fab55b5bd77344ee82b0132fd3fa2451",
            "0c26d112acdf4e3bbf299c0f98f5e567",
            "e6aecf83d35f4edfb9719b701f08a9a1",
            "1c82df4d6827453fbdaad814063ec24c",
            "16c38788dd6148eb8112f42ee5213faf",
            "2f8aa7242a4249d0938cd7e8edb2bd77",
            "fac2af1f489742719169cd5d5cf7df4a",
            "570ef5c481d141049a0d29fb7d45207c",
            "fd32557768134772a9c97e37067005e7",
            "0727e443119643a29047bb8fab59e69f",
            "cc1b997ed6bd4c1ca73ea37ba5f49e57",
            "6e2722a431704d9aa2a01f6bb74d1241",
            "b2d0d5f0df404971a58c9adfb98234af",
            "98a1098fd87f419692a8cbd22c6bd03f",
            "efcb936c098c432490b08612ac981183",
            "ebd94bd9770449d299c03b0f9ef5dc2b",
            "c8eeae4e234046e8b663faa32d509ea4",
            "87bb06c4cd8f4bce987ca2418cbcc083",
            "33becbb84e494b148f596124d9cc7878",
            "bc52d7925b5349549d97bd96f465b219",
            "6fb9991a8f954063bc039848be8ea384",
            "6f3c043348bf45f0b4273a0ad27d81cc",
            "ac240026973248ce9974d5879f444cdb",
            "c9ade3ca5fdf4e6a8bf9970cf32de185",
            "96cca5b75239461c888bb995e7fe0336",
            "d713038f847f405a88c8eb977c818c1b",
            "a89c3cc4c5d841faae0d14d93099bade",
            "0beedc4214bb459d8695c47e2d55f3e3",
            "a9ac744fd4cd40099aeb061fa3c521f0",
            "9f496c5f4df5437a993db280a4c4e855",
            "342f6c2f3a7b49e99801bcc3d0f26893",
            "11989a6f647a4172a59a91615894568a",
            "0e751a5c6ae64b478970f0eb61afa5b9",
            "077794ad705f42a3a1f2ab62bffb95fa",
            "0d4229346858411faa8f444cf19ed6d9",
            "6eb8dad30a934f9f980ca4ea16dd3182",
            "ec472b7c0866451fa5613c8145fdbd6b",
            "0ddab2d139f64dd7872353bce8b5020c",
            "3838d1a1cb284dd8a71a778b62af6b7c",
            "eddcbc7ceae7421fbf7739f40e8a8689",
            "2d5e9724e7bc488497c5027f727e3cec",
            "6d70c09022aa4202970922e9b7e1f9a6",
            "3d58cd41857941d9aa81f18676c03242",
            "84cb40072e8b4919b9ee9727d17b93f6",
            "cfe515aacce94d48bccb51c93b950b6e",
            "64fca84285234a55997a1c6af4f47f1a",
            "4682c0467e3c4e16ae800e070219306a",
            "1afa0370ddf64563afeb9f105c0f2146",
            "e9d91bf3f3b04ed6bef10310cb14811d",
            "9c657a581668497083a71cf6a9ebd215",
            "55622f38317d46358000efe50f085b48",
            "041d7143669749c1901e6748b697cca4",
            "54c5b57e562d4dfcb1e219865266253b",
            "a460b8859dd445fe869a3b54bfe3a2a7",
            "02a45277ea51406f8abae2293a1dee75",
            "e20fcb298c1d42c5a022996d4fd86797",
            "e18964eead7c4eaca094bb32597f37f8",
            "704760d456bf4223b53cb77356d34dfb",
            "69f6afa9613b412d9ee23d36ac2f3820",
            "19e1202c1dc44a969504198a32e7fd91",
            "9487f16f4e314fea9db8d80d6ef7fa0d",
            "c0db38660a274cd2ad50feb86db09820",
            "9737c9f288d34d37af3d3e6ed5dbcc4a",
            "23df33d962b342e7a1d29f2db8a853b4",
            "01ecc409119d4ea7a8e629518c3a899d",
            "b136bcfbd37e45279104b48d66aec4fc",
            "b881c1cebf0949359fe687f5ecd6a418"
          ]
        },
        "id": "G_FNrXjEiNXG",
        "outputId": "56b945fe-7276-461c-a926-a70b9bb9713b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d286c5534ca479d8bf6ab9b06a9b5d7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/31.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c26d112acdf4e3bbf299c0f98f5e567",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(‚Ä¶)c5cdr_train_hypencoder_contrastive.jsonl: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2d0d5f0df404971a58c9adfb98234af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bc5cdr_val_hypencoder_contrastive.jsonl: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9ade3ca5fdf4e6a8bf9970cf32de185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bc5cdr_test_hypencoder_contrastive.jsonl: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d4229346858411faa8f444cf19ed6d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/2654 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64fca84285234a55997a1c6af4f47f1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/2559 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e18964eead7c4eaca094bb32597f37f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/2656 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# loading the data\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"Stevenf232/hypencoder_contrastiveLoss_nameOnly\")\n",
        "train_data = dataset['train']\n",
        "val_data = dataset['validation']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "7afef0a52408478f9792d4ecef2351d1",
            "e57d3fcf761c49518e0514f6fbacdf5a",
            "af37a74157ef4edf9268750cf8a658bc",
            "a3b18c64b36b4ebebed74e901f95f44e",
            "6adbb187d83c443ab429bd6a2fbdec3c",
            "5642ca1db6e349399440ddef1b13c320",
            "3811c4d1dcfa428ba3d9dddc083e938d",
            "3a3a4887bfae48c8b53053bfb987c944",
            "f6d1b7df82bd4710addb78d486e1f338",
            "71dc7e6e5da34471b4eb3dbe4f6fe336",
            "42f71f6da4a64270900c3681c843b7d0",
            "b13e5c957cf8477fa799ba9a56547868",
            "0a2c91865c154a548711e25bd41ef8bb",
            "89dfc156ac9642668c5b46e9ca962868",
            "d1684ecd907b4728b5d12c96c3412a61",
            "3bf36d0ab0f34d1583370c8db7284d23",
            "ef3dcdad83264e3e91c01bcb17f73e2a",
            "8f73f43d6e3c451f84ff3148640dff2d",
            "8ec8f0b2d994440da6c1118fa93e9ae8",
            "d2bd6aa3b36c441aa05df8edd3a3fb58",
            "2751996860bd467086d0055026f4c64e",
            "2da090d6e5c940d6aa31bebd2acdfb7c"
          ]
        },
        "id": "fMNsKxUIk7RH",
        "outputId": "5fcb65dc-374b-48ba-87b1-a1c0fd954f17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7afef0a52408478f9792d4ecef2351d1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b13e5c957cf8477fa799ba9a56547868",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating json from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "307335"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# saving the data to a file\n",
        "train_data.to_json('data/train.jsonl', lines=True)\n",
        "val_data.to_json('data/val.jsonl', lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4AMOHZKiDFf",
        "outputId": "5fcf3a5f-0f75-4d25-d7d0-d407907c324e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rtokenizer_config.json:   0% 0.00/198 [00:00<?, ?B/s]\rtokenizer_config.json: 100% 198/198 [00:00<00:00, 1.67MB/s]\n",
            "config.json: 100% 462/462 [00:00<00:00, 4.61MB/s]\n",
            "vocab.txt: 226kB [00:00, 18.7MB/s]\n",
            "special_tokens_map.json: 100% 112/112 [00:00<00:00, 1.06MB/s]\n",
            "2654it [00:00, 382926.83it/s]\n",
            "2it [00:00, 42.33it/s]\n",
            "2it [00:00, 63.15it/s]\n",
            "2654it [00:00, 54039.66it/s]\n",
            "2559it [00:00, 391938.07it/s]\n",
            "2it [00:00, 83.14it/s]\n",
            "2it [00:00, 84.90it/s]\n",
            "2559it [00:00, 46543.16it/s]\n"
          ]
        }
      ],
      "source": [
        "# tokenizing the data before training\n",
        "\n",
        "# training\n",
        "!python hypencoder_cb/utils/tokenizer_utils.py \\\n",
        "--standard_format_jsonl='data/train.jsonl' \\\n",
        "--output_file='data/train_tokenized.jsonl' \\\n",
        "--tokenizer=\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\" \\\n",
        "--add_special_tokens=True \\\n",
        "--query_max_length=32 \\\n",
        "--item_max_length=512\n",
        "\n",
        "# validation\n",
        "!python hypencoder_cb/utils/tokenizer_utils.py \\\n",
        "--standard_format_jsonl='data/val.jsonl' \\\n",
        "--output_file='data/val_tokenized.jsonl' \\\n",
        "--tokenizer=\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\" \\\n",
        "--add_special_tokens=True \\\n",
        "--query_max_length=32 \\\n",
        "--item_max_length=512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8nHbTeyNbW2"
      },
      "source": [
        "Everything in the output above is [00:00] which seems quite suspicious! (or it could just be really fast)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9p1RZWQNkp3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMwS-qhVRuDu",
        "outputId": "cb80ea82-61f3-4fe9-8393-caa3058ca238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cls [CLS] 2\n",
            "sep [SEP] 3\n",
            "pad [PAD] 0\n",
            "bos None None\n",
            "eos None None\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\", use_fast=True)\n",
        "print(\"cls\", tok.cls_token, tok.cls_token_id)\n",
        "print(\"sep\", tok.sep_token, tok.sep_token_id)\n",
        "print(\"pad\", tok.pad_token, tok.pad_token_id)\n",
        "print(\"bos\", tok.bos_token, tok.bos_token_id)\n",
        "print(\"eos\", tok.eos_token, tok.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85hBzqvUObgw"
      },
      "source": [
        "Training the hypencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKk1A5IZNe6q",
        "outputId": "91279237-5577-4bfb-c1f6-9a4c0ba9599c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-31 21:33:38.639316: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1767216818.659578   10343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1767216818.665965   10343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1767216818.682648   10343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767216818.682672   10343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767216818.682676   10343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1767216818.682681   10343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-31 21:33:38.689211: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "{'model_config': {'tokenizer_pretrained_model_name_or_path': 'cambridgeltl/SapBERT-from-PubMedBERT-fulltext', 'query_encoder_kwargs': {'model_name_or_path': 'cambridgeltl/SapBERT-from-PubMedBERT-fulltext', 'freeze_transformer': True, 'embedding_representation': None, 'base_encoder_output_dim': 768, 'converter_kwargs': {'vector_dimensions': [768, 768, 768, 1], 'activation_type': 'relu', 'do_residual_on_last': False}}, 'passage_encoder_kwargs': {'model_name_or_path': 'cambridgeltl/SapBERT-from-PubMedBERT-fulltext', 'freeze_transformer': True, 'pooling_type': 'cls'}, 'loss_type': ['cross_entropy'], 'loss_kwargs': [{'use_in_batch_negatives': True, 'only_use_first_item': False}], 'checkpoint_path': None, 'model_type': 'hypencoder', 'shared_encoder': True}, 'data_config': {'training_data_jsonl': 'data/train_tokenized.jsonl', 'validation_data_jsonl': 'data/val_tokenized.jsonl', 'training_huggingface_dataset': None, 'validation_huggingface_dataset': None, 'training_data_split': 'train', 'validation_data_split': 'train', 'positive_filter_type': 'first', 'positive_filter_kwargs': None, 'label_key': None, 'num_positives_to_sample': 1, 'num_negatives_to_sample': 0}, 'trainer_config': {'hf_trainer_config': {'output_dir': 'model/hypencoder.2_layer_SapBERT', 'overwrite_output_dir': False, 'remove_unused_columns': False, 'eval_strategy': 'no', 'eval_steps': 500, 'per_device_train_batch_size': 64, 'per_device_eval_batch_size': 64, 'gradient_accumulation_steps': 1, 'dataloader_num_workers': 1, 'dataloader_persistent_workers': False, 'dataloader_prefetch_factor': 5, 'ignore_data_skip': False, 'learning_rate': 2e-05, 'weight_decay': 0.0, 'num_train_epochs': 10, 'lr_scheduler_type': 'linear', 'warmup_ratio': 0.1, 'warmup_steps': 0, 'logging_strategy': 'steps', 'logging_steps': 10, 'max_steps': -1, 'save_strategy': 'steps', 'save_steps': 2500, 'save_total_limit': None, 'save_only_model': False, 'save_safetensors': False, 'bf16': False, 'fp16': False, 'tf32': False, 'torch_compile': False, 'torch_compile_mode': 'default', 'run_name': 'hypencoder.2_layer_SapBERT', 'disable_tqdm': True, 'ddp_find_unused_parameters': True, 'report_to': 'none', 'push_to_hub': False, 'hub_model_id': None, 'hub_strategy': 'every_save', 'hub_private_repo': True, 'gradient_checkpointing': False, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_epsilon': 1e-08}, 'resume_from_checkpoint': False}}\n",
            "Generating train split: 2654 examples [00:00, 160853.17 examples/s]\n",
            "Model loaded\n",
            "\n",
            "data collated\n",
            "\n",
            "The speedups for torchdynamo mostly come with GPU Ampere or higher and which is not detected here.\n",
            "training arguments loaded\n",
            "\n",
            "/content/Hypencoder-Entity-Linking/hypencoder-paper/hypencoder_cb/train/train.py:171: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Starting training\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 0}.\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] Graph break from `Tensor.item()`, consider setting:\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0]     torch._dynamo.config.capture_scalar_outputs = True\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] or:\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0]     env TORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] to include these operations in the captured graph.\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] \n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] Graph break: from user code at:\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0]   File \"/content/Hypencoder-Entity-Linking/hypencoder-paper/hypencoder_cb/modeling/shared.py\", line 153, in forward\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0]     to_log[\"similarity_loss\"] = loss.item()\n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] \n",
            "W1231 21:33:52.504000 10343 torch/_dynamo/variables/tensor.py:1048] [0/0] \n",
            "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n",
            "W1231 21:34:03.487000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/1] _maybe_guard_rel() was called on non-relation expression Eq(s0, s52) | Eq(s52, 1)\n",
            "W1231 21:34:06.241000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/1] _maybe_guard_rel() was called on non-relation expression Eq(s55, 1) | Eq(s74, s55)\n",
            "W1231 21:34:08.139000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/1_1] _maybe_guard_rel() was called on non-relation expression Eq(s0, s52) | Eq(s52, 1)\n",
            "W1231 21:34:11.669000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/1_1] _maybe_guard_rel() was called on non-relation expression Eq(s55, 1) | Eq(s74, s55)\n",
            "{'loss': 4.6121, 'grad_norm': 107.36187744140625, 'learning_rate': 4.5e-06, 'epoch': 0.25}\n",
            "{'loss': 4.1314, 'grad_norm': 81.77188110351562, 'learning_rate': 9.5e-06, 'epoch': 0.5}\n",
            "{'loss': 3.2993, 'grad_norm': 82.85482788085938, 'learning_rate': 1.45e-05, 'epoch': 0.75}\n",
            "W1231 21:34:29.264000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2] _maybe_guard_rel() was called on non-relation expression Eq(s77, s94) | Eq(s94, 1)\n",
            "W1231 21:34:29.266000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2] _maybe_guard_rel() was called on non-relation expression Eq(s0, s52) | Eq(s52, 1)\n",
            "W1231 21:34:32.535000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2] _maybe_guard_rel() was called on non-relation expression Eq(s2, s92) | Eq(s92, 1)\n",
            "W1231 21:34:32.538000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2] _maybe_guard_rel() was called on non-relation expression Eq(s55, 1) | Eq(s74, s55)\n",
            "W1231 21:34:35.641000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2_1] _maybe_guard_rel() was called on non-relation expression Eq(s77, s94) | Eq(s94, 1)\n",
            "W1231 21:34:35.645000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2_1] _maybe_guard_rel() was called on non-relation expression Eq(s0, s52) | Eq(s52, 1)\n",
            "W1231 21:34:39.116000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2_1] _maybe_guard_rel() was called on non-relation expression Eq(s2, s92) | Eq(s92, 1)\n",
            "W1231 21:34:39.118000 10343 torch/fx/experimental/symbolic_shapes.py:6833] [0/2_1] _maybe_guard_rel() was called on non-relation expression Eq(s55, 1) | Eq(s74, s55)\n",
            "{'loss': 2.3656, 'grad_norm': 63.60570526123047, 'learning_rate': 1.95e-05, 'epoch': 1.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 1.2769, 'grad_norm': 46.48249816894531, 'learning_rate': 1.95e-05, 'epoch': 1.25}\n",
            "{'loss': 0.7619, 'grad_norm': 44.416969299316406, 'learning_rate': 1.8944444444444447e-05, 'epoch': 1.5}\n",
            "{'loss': 0.4734, 'grad_norm': 36.2529296875, 'learning_rate': 1.838888888888889e-05, 'epoch': 1.75}\n",
            "{'loss': 0.3357, 'grad_norm': 25.273788452148438, 'learning_rate': 1.7833333333333334e-05, 'epoch': 2.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.1776, 'grad_norm': 23.972837448120117, 'learning_rate': 1.727777777777778e-05, 'epoch': 2.25}\n",
            "{'loss': 0.173, 'grad_norm': 32.60515594482422, 'learning_rate': 1.6722222222222225e-05, 'epoch': 2.5}\n",
            "{'loss': 0.1374, 'grad_norm': 11.92000961303711, 'learning_rate': 1.616666666666667e-05, 'epoch': 2.75}\n",
            "{'loss': 0.1166, 'grad_norm': 32.889869689941406, 'learning_rate': 1.5611111111111113e-05, 'epoch': 3.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.1058, 'grad_norm': 13.984763145446777, 'learning_rate': 1.5055555555555556e-05, 'epoch': 3.25}\n",
            "{'loss': 0.0893, 'grad_norm': 9.11774730682373, 'learning_rate': 1.45e-05, 'epoch': 3.5}\n",
            "{'loss': 0.0994, 'grad_norm': 10.404315948486328, 'learning_rate': 1.3944444444444446e-05, 'epoch': 3.75}\n",
            "{'loss': 0.0954, 'grad_norm': 39.227901458740234, 'learning_rate': 1.338888888888889e-05, 'epoch': 4.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0884, 'grad_norm': 14.942120552062988, 'learning_rate': 1.2833333333333335e-05, 'epoch': 4.25}\n",
            "{'loss': 0.0724, 'grad_norm': 12.529537200927734, 'learning_rate': 1.227777777777778e-05, 'epoch': 4.5}\n",
            "{'loss': 0.0805, 'grad_norm': 7.07827091217041, 'learning_rate': 1.1722222222222224e-05, 'epoch': 4.75}\n",
            "{'loss': 0.0919, 'grad_norm': 26.651918411254883, 'learning_rate': 1.1166666666666668e-05, 'epoch': 5.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0732, 'grad_norm': 13.577973365783691, 'learning_rate': 1.0611111111111111e-05, 'epoch': 5.25}\n",
            "{'loss': 0.0648, 'grad_norm': 12.209450721740723, 'learning_rate': 1.0055555555555557e-05, 'epoch': 5.5}\n",
            "{'loss': 0.0672, 'grad_norm': 33.70127487182617, 'learning_rate': 9.5e-06, 'epoch': 5.75}\n",
            "{'loss': 0.0742, 'grad_norm': 21.313919067382812, 'learning_rate': 8.944444444444446e-06, 'epoch': 6.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0528, 'grad_norm': 21.87645721435547, 'learning_rate': 8.38888888888889e-06, 'epoch': 6.25}\n",
            "{'loss': 0.0646, 'grad_norm': 14.795717239379883, 'learning_rate': 7.833333333333333e-06, 'epoch': 6.5}\n",
            "{'loss': 0.0662, 'grad_norm': 17.657751083374023, 'learning_rate': 7.277777777777778e-06, 'epoch': 6.75}\n",
            "{'loss': 0.0852, 'grad_norm': 9.89352035522461, 'learning_rate': 6.7222222222222235e-06, 'epoch': 7.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0672, 'grad_norm': 10.50017261505127, 'learning_rate': 6.166666666666667e-06, 'epoch': 7.25}\n",
            "{'loss': 0.0807, 'grad_norm': 16.115074157714844, 'learning_rate': 5.611111111111112e-06, 'epoch': 7.5}\n",
            "{'loss': 0.056, 'grad_norm': 15.634113311767578, 'learning_rate': 5.0555555555555555e-06, 'epoch': 7.75}\n",
            "{'loss': 0.0576, 'grad_norm': 4.4182329177856445, 'learning_rate': 4.5e-06, 'epoch': 8.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0759, 'grad_norm': 22.3959903717041, 'learning_rate': 3.944444444444445e-06, 'epoch': 8.25}\n",
            "{'loss': 0.0346, 'grad_norm': 10.154661178588867, 'learning_rate': 3.3888888888888893e-06, 'epoch': 8.5}\n",
            "{'loss': 0.0577, 'grad_norm': 4.109118938446045, 'learning_rate': 2.8333333333333335e-06, 'epoch': 8.75}\n",
            "{'loss': 0.0587, 'grad_norm': 5.147540092468262, 'learning_rate': 2.277777777777778e-06, 'epoch': 9.0}\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
            "{'loss': 0.0507, 'grad_norm': 8.975791931152344, 'learning_rate': 1.7222222222222224e-06, 'epoch': 9.25}\n",
            "{'loss': 0.0496, 'grad_norm': 25.286869049072266, 'learning_rate': 1.1666666666666668e-06, 'epoch': 9.5}\n",
            "{'loss': 0.0576, 'grad_norm': 13.948539733886719, 'learning_rate': 6.111111111111112e-07, 'epoch': 9.75}\n",
            "{'loss': 0.08, 'grad_norm': 20.6357421875, 'learning_rate': 5.555555555555556e-08, 'epoch': 10.0}\n",
            "{'train_runtime': 158.6072, 'train_samples_per_second': 161.342, 'train_steps_per_second': 2.522, 'train_loss': 0.49646166518330576, 'epoch': 10.0}\n"
          ]
        }
      ],
      "source": [
        "!python hypencoder_cb/train/train.py hypencoder_cb/train/configs/hypencoder.2_layer_SapBERT.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758,
          "referenced_widgets": [
            "24d40d41650744c3b6f60338f9f4d7c4",
            "898a4b443a544e7184e231596e2ea2fe",
            "69447223c5094eadba53f1d14a6e2720",
            "75141848632b4f999213d6350f73eb15",
            "08228d98dc564c0bacceced35a5dfa18",
            "75ba5a7bdd0f4dd8a2c89c9f97117aa5",
            "84a24309fa2f4f4dac3df923a3bc98e8",
            "39086907f9fc4906b8ea74bd40394883",
            "44d9d1d8b5724fa7a7f20375c5fc5fe5",
            "384679a1c8b94bc7bb681e2bfd068b33",
            "f3115f973a5d470c8d8a9e335a44ad7b",
            "a624d410990e43309053ec35f1518f6f",
            "3e1b6b0a63de4d128cf63ce5823b9f70",
            "8cf89d47f61b4db2b7291af21b5dc10b",
            "9bbb6db02e684631b58c59a1fa1022d9",
            "ab50ac5444294d8b9d5cbf05e6fb1840",
            "e200ae0ac00849ed90e75c2784e69b6e",
            "cc392ceea4a0400095fb27913c7bcdf3",
            "1b6ebd89b6f64393a99e90f217d8837d",
            "b365ed6607c44bfa8ca923e622c04314",
            "3d2fdbfffdbe4847aba586086306c412",
            "467e5a5f99e74c2ebad90f9d0befd7af",
            "75d502215d0b4196b0f46a129dbb4874",
            "444b80e90dd04990bce6c1f1b47bfa92",
            "04371a4064944db8b6b257f23e5c8d88",
            "01800c1ba4b041bda644a73dae25d41d",
            "13a4892fee574a0b8055eb5b8ee290b3",
            "ea6f14fdd550468f882702c6099a4ecc",
            "506d64e3914f4f3faa62e511d14e165b",
            "c0d230f3aa344fc4b96a468e0ab677a3",
            "f7701895ea04450bb68d37af4d066002",
            "cb669c3a8b174e3fb5f0d3fbe1654eb8",
            "0d2177f5f01d4e12bb39c0f7ed7a5349",
            "34f94a35d8df4b1c938c47581e6b8d23",
            "a7e043925c55429c86891bb4334875b2",
            "fb2f3bffcf9f4d34b0b74205c93ba80e",
            "9a5881c542f34adcaee25930db0223ba",
            "8eb9dff851554c07b16d07b7e8fd4ae5",
            "2e1c00209e3d4fcc8bbfaca433b4575a",
            "66e833a506224298bef3058ab769b702",
            "6c9c1ba5582e4ddc85518e86a168a54a",
            "6c49426f355247d092016dcb59f58b57",
            "40d7251f8bdd4e0f8815dbdbd0c30474",
            "a9ebbd63f5da431cac026c330338c9d9",
            "b49b4c304bc44f5fb8448caa6764fc8a",
            "c8bdb060ad0b422b86eab10fba0a6002",
            "8341dc39d6a9478baa8bb935e569fdf3",
            "41a1486adb654b56811b10e0ee4cf07d",
            "982550703dcf4eada130fa4e324bae58",
            "0049ea7e2cc94502a31bcd7caadd812f",
            "83225df7ba264903b66f2cccbad4b16f",
            "6b9d12ae23684c9ab71907cdb553c993",
            "ba37b80fd01742d888737227b8765b55",
            "1290e4ee6a81472f9ec46d71575e7225",
            "ce1665b9e31a4fb1b0e3f79ff3e884b9",
            "f0bd6eddd52e426d90de9eadc4d20867",
            "6ee88932df5e49dcaec685bacc3e9ad8",
            "3c4d88c5e99b4a96a15b8261f8869d5b",
            "85e7a0c7a42b4c8894b2b16e2ea745ad",
            "5443fce28d54418ab67f2c1918ef0a93",
            "c32c1f95ab9349a5bb7591d2cee0f450",
            "937d60066fce4687a137ff08f005cebe",
            "0d36242ad622435789186d7dddcca547",
            "696f3c83bf2847d89a4eca3dc3dbf54c",
            "dfe34c3c9e6c438298486dc5da23fa65",
            "b11cb2ba11cc4eb78db38f6bff44ff1b",
            "ea5b864acfbf4bbcb2b41d8e6fb071fa",
            "0f8f2f4b3fb446d6a140f1a698675e06",
            "be89309484ec4a6b8365a003601bc6d5",
            "55b82a89669c418596ae27ef0b545053",
            "ad6ce666da9d44df8265930bce48ff93",
            "4cd392348dc64894b6df6316235ebc92",
            "4ef762f22612444f8907eeb7fb686af2",
            "4725ce6704d14297a8082dc1eda2c2a7",
            "9a34f158fea740c0bfafc55253c961a5",
            "f28db69b1e9948488634ec4c225d5f4d",
            "6335d9c56b604fcc87636bb4c392a394"
          ]
        },
        "id": "mQZV22a_S-oW",
        "outputId": "909858b3-59b1-4588-cb41-132e05fc0609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub) (2025.11.12)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24d40d41650744c3b6f60338f9f4d7c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a624d410990e43309053ec35f1518f6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload               : |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75d502215d0b4196b0f46a129dbb4874",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...eckpoint-400/scheduler.pt: 100%|##########| 1.47kB / 1.47kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34f94a35d8df4b1c938c47581e6b8d23",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...ckpoint-400/rng_state.pth:  77%|#######7  | 11.3kB / 14.6kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b49b4c304bc44f5fb8448caa6764fc8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...int-400/pytorch_model.bin:   0%|          | 1.53MB /  483MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0bd6eddd52e426d90de9eadc4d20867",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...eckpoint-400/optimizer.pt:   1%|          |  579kB / 89.8MB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea5b864acfbf4bbcb2b41d8e6fb071fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  ...int-400/training_args.bin:   6%|6         |   368B / 5.91kB            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Stevenf232/SapBERT_freeze_hypencoder/commit/8f8fc2b8a653287206056c00872c6e6eafbad5bc', commit_message='Upload trained model from Colab', commit_description='', oid='8f8fc2b8a653287206056c00872c6e6eafbad5bc', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Stevenf232/SapBERT_freeze_hypencoder', endpoint='https://huggingface.co', repo_type='model', repo_id='Stevenf232/SapBERT_freeze_hypencoder'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install huggingface_hub\n",
        "\n",
        "# push the model to HuggingFace\n",
        "# the model was saved in the model directory\n",
        "\n",
        "from huggingface_hub import upload_folder\n",
        "\n",
        "# Path where your model files (weights, config, etc.) are saved in Colab\n",
        "# CHANGE THE CHECKPOINT NUMBER APPROPRIATELY\n",
        "local_folder_path = \"model/hypencoder.2_layer_SapBERT/checkpoint-400\"\n",
        "\n",
        "# Your desired repository ID on Hugging Face (e.g., \"your-username/my-generic-model\")\n",
        "repo_id = \"Stevenf232/SapBERT_freeze_hypencoder\"\n",
        "\n",
        "# You may need to create the repository first if it doesn't exist\n",
        "from huggingface_hub import create_repo\n",
        "create_repo(repo_id, exist_ok=True)\n",
        "\n",
        "upload_folder(\n",
        "    folder_path=local_folder_path,\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\", # or \"dataset\" or \"space\"\n",
        "    commit_message=\"Upload trained model from Colab\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
